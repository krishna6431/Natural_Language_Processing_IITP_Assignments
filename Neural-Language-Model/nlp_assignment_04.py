# -*- coding: utf-8 -*-
"""NLP_Assignment_04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11_UaKRB2_7OFHCNFK5adE_V7GtZK1tK2

#NLP Assignmnet 4 <br>
Name : Krishna Kant Verma</br>
Roll No: 2211cs19</br>
Name : Gourab Chatterjee</br>
Roll No: 2211cs08

`Importing libraries Used for this Assignmnemt`
"""

import numpy as np
import tensorflow as tf
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
import keras.backend as K
from keras.callbacks import EarlyStopping
from keras.utils import to_categorical
from keras.layers import Dense,SimpleRNN
from keras.models import Sequential

"""`Reading text dataset file`"""

with open("names.txt",'r') as f:
    data=f.readlines()
data=[text.strip('\n')+'.' for text in data]

"""#Creating Dataset"""

def createDataset(data,ngram):
    X=[]
    Y=[]
    for text in data:
        pointer=0
        while pointer+ngram<len(text):
            X.append(text[pointer:pointer+ngram])
            Y.append(text[pointer+ngram])
            pointer+=1
    ctoi={char:ind for ind,char in enumerate(sorted(set(Y)))}

    X = [[to_categorical(ctoi[charector],27) for charector in  text_data] for text_data in X]
    X = np.array(X)
    Y = [to_categorical(ctoi[charector],27) for charector in Y]
    Y = np.array(Y)
    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))
    fd=np.concatenate([X,Y],axis=1)
    np.random.shuffle(fd)
    part1=int(fd.shape[0]*0.9)
    part2=part1+int(fd.shape[0]*0.05)
    return np.split(fd,[part1,part2]),ctoi

def createModel(ngram):
    def perplexityLoss(y_true, y_pred):
        crossEntropyError = K.categorical_crossentropy(y_true, y_pred)
        perplexity = K.pow(np.e, crossEntropyError)
        return perplexity

    model = Sequential([
        Dense(128,input_shape=(27*ngram,),activation='relu'),
        Dense(64,activation='relu'),
        Dense(27,activation='softmax'),
    ])

    model.compile(optimizer='adam',loss=perplexityLoss,metrics=['accuracy'])
    return model

"""# Bi-Gram Model"""

earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', restore_best_weights=True)
(train,test,val),ctoi=createDataset(data,2)

model_2gram = createModel(2)
gram2His = model_2gram.fit(train[:,:27*2],train[:,27*2:],
                  validation_data=[val[:,:27*2],val[:,27*2:]],
                  epochs=30,callbacks=[earlyStopping])

"""#Tri-Gram-Model"""

(train,test,val),ctoi=createDataset(data,3)
m3gram = createModel(3)
gram3His = m3gram.fit(train[:,:27*3],train[:,27*3:],
                  validation_data=[val[:,:27*3],val[:,27*3:]],
                  epochs=30,callbacks=[earlyStopping])

earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', restore_best_weights=True)
def create_RNN_model(ngram):
    def perplexityLoss(y_true, y_pred):
        crossEntropyError = K.categorical_crossentropy(y_true, y_pred)
        perplexity = K.pow(np.e, crossEntropyError)
        return perplexity
    model = Sequential([
        SimpleRNN(128,input_shape=(ngram,27),activation='relu'),
        Dense(27,activation='softmax'),
    ])

    model.compile(optimizer='adam',loss=perplexityLoss,metrics=['accuracy'])
    return model

ngram = 3
(train,test,val),ctoi=createDataset(data,ngram)
m2RNNgram = create_RNN_model(ngram)
m2RNNgram.fit(train[:,:27*ngram].reshape(train.shape[0],ngram,27),train[:,27*ngram:],
          validation_data=[val[:,:27*ngram].reshape(val.shape[0],ngram,27),val[:,27*ngram:]],
          epochs=30,callbacks=[earlyStopping])

"""#Plots"""

import matplotlib.pyplot as plt
plt.plot([x for x in range(len(gram2His.history['loss']))],gram2His.history['loss'],c='b')
plt.title("Epochs vs perplexityLoss for 2gram")
plt.x_label="Epochs"
plt.y_label="Loss"
plt.show()
plt.plot([x for x in range(len(gram2His.history['accuracy']))],gram2His.history['accuracy'],c='r')
plt.title("Epochs vs accuracy for 2gram")
plt.x_label="Epochs"
plt.y_label="Loss"
plt.show()
plt.plot([x for x in range(len(gram3His.history['loss']))],gram3His.history['loss'],c='g')
plt.title("Epochs vs perplexityLoss for 3gram")
plt.x_label="Epochs"
plt.y_label="Loss"
plt.show()
plt.plot([x for x in range(len(gram3His.history['accuracy']))],gram3His.history['accuracy'],c='y')
plt.title("Epochs vs accuracy for 3gram")
plt.x_label="Epochs"
plt.y_label="Loss"
plt.show()

"""#Thank You So Much"""